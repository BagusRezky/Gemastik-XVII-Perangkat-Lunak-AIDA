{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from imutils.video import FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\rizky\\anaconda3\\lib\\site-packages (8.1.28)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from ultralytics) (3.7.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from ultralytics) (4.8.0.76)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from ultralytics) (9.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from ultralytics) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from ultralytics) (1.10.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from ultralytics) (2.2.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from ultralytics) (0.17.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from ultralytics) (4.65.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\rizky\\appdata\\roaming\\python\\python311\\site-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from ultralytics) (8.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from ultralytics) (1.5.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from ultralytics) (0.12.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rizky\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.3.0->ultralytics) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rizky\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2022.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
      "Requirement already satisfied: filelock in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2023.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rizky\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rizky\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\rizky\\anaconda3\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class Tracker:\n",
    "    def __init__(self):\n",
    "        # Store the center positions of the objects\n",
    "        self.center_points = {}\n",
    "        # Keep the count of the IDs\n",
    "        # each time a new object id detected, the count will increase by one\n",
    "        self.id_count = 0\n",
    "\n",
    "\n",
    "    def update(self, objects_rect):\n",
    "        # Objects boxes and ids\n",
    "        objects_bbs_ids = []\n",
    "\n",
    "        # Get center point of new object\n",
    "        for rect in objects_rect:\n",
    "            x, y, w, h = rect\n",
    "            cx = (x + x + w) // 2\n",
    "            cy = (y + y + h) // 2\n",
    "\n",
    "            # Find out if that object was detected already\n",
    "            same_object_detected = False\n",
    "            for id, pt in self.center_points.items():\n",
    "                dist = math.hypot(cx - pt[0], cy - pt[1])\n",
    "\n",
    "                if dist < 35:\n",
    "                    self.center_points[id] = (cx, cy)\n",
    "#                    print(self.center_points)\n",
    "                    objects_bbs_ids.append([x, y, w, h, id])\n",
    "                    same_object_detected = True\n",
    "                    break\n",
    "\n",
    "            # New object is detected we assign the ID to that object\n",
    "            if same_object_detected is False:\n",
    "                self.center_points[self.id_count] = (cx, cy)\n",
    "                objects_bbs_ids.append([x, y, w, h, self.id_count])\n",
    "                self.id_count += 1\n",
    "\n",
    "        # Clean the dictionary by center points to remove IDS not used anymore\n",
    "        new_center_points = {}\n",
    "        for obj_bb_id in objects_bbs_ids:\n",
    "            _, _, _, _, object_id = obj_bb_id\n",
    "            center = self.center_points[object_id]\n",
    "            new_center_points[object_id] = center\n",
    "\n",
    "        # Update dictionary with IDs not used removed\n",
    "        self.center_points = new_center_points.copy()\n",
    "        return objects_bbs_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=YOLO('yolov8s.pt')\n",
    "# model=YOLO('yolov8m.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x640 1 person, 3 cars, 1 fire hydrant, 2655.0ms\n",
      "Speed: 24.9ms preprocess, 2655.0ms inference, 32.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 1 fire hydrant, 1046.8ms\n",
      "Speed: 20.9ms preprocess, 1046.8ms inference, 15.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 1 fire hydrant, 1198.3ms\n",
      "Speed: 28.9ms preprocess, 1198.3ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 1 fire hydrant, 1698.1ms\n",
      "Speed: 15.0ms preprocess, 1698.1ms inference, 6.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 1 fire hydrant, 699.6ms\n",
      "Speed: 119.2ms preprocess, 699.6ms inference, 8.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[]\n",
      "[359, 350]\n",
      "\n",
      "0: 320x640 3 cars, 1 fire hydrant, 731.6ms\n",
      "Speed: 16.0ms preprocess, 731.6ms inference, 7.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[]\n",
      "[250, 12]\n",
      "[250, 10]\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 1 fire hydrant, 785.3ms\n",
      "Speed: 32.9ms preprocess, 785.3ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 1 fire hydrant, 699.6ms\n",
      "Speed: 5.0ms preprocess, 699.6ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1]\n",
      "[168, 132]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 1 fire hydrant, 652.5ms\n",
      "Speed: 6.0ms preprocess, 652.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1]\n",
      "[163, 155]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 1 fire hydrant, 680.2ms\n",
      "Speed: 23.9ms preprocess, 680.2ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1]\n",
      "\n",
      "0: 320x640 3 cars, 1 fire hydrant, 825.9ms\n",
      "Speed: 7.0ms preprocess, 825.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1]\n",
      "[9, 410]\n",
      "\n",
      "0: 320x640 3 cars, 1 fire hydrant, 632.3ms\n",
      "Speed: 8.0ms preprocess, 632.3ms inference, 9.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 626.9ms\n",
      "Speed: 13.0ms preprocess, 626.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 622.5ms\n",
      "Speed: 4.0ms preprocess, 622.5ms inference, 10.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1]\n",
      "[466, 144]\n",
      "[482, 144]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 700.7ms\n",
      "Speed: 12.0ms preprocess, 700.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1]\n",
      "\n",
      "0: 320x640 3 cars, 670.4ms\n",
      "Speed: 31.9ms preprocess, 670.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1]\n",
      "\n",
      "0: 320x640 2 cars, 592.5ms\n",
      "Speed: 11.0ms preprocess, 592.5ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1]\n",
      "[805, 37]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 787.5ms\n",
      "Speed: 32.9ms preprocess, 787.5ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 567.5ms\n",
      "Speed: 16.9ms preprocess, 567.5ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 588.1ms\n",
      "Speed: 5.0ms preprocess, 588.1ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0]\n",
      "[480, 14]\n",
      "[472, 5]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 564.5ms\n",
      "Speed: 6.0ms preprocess, 564.5ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 649.3ms\n",
      "Speed: 14.0ms preprocess, 649.3ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 657.9ms\n",
      "Speed: 3.0ms preprocess, 657.9ms inference, 6.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0]\n",
      "[506, 339]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 776.5ms\n",
      "Speed: 98.7ms preprocess, 776.5ms inference, 7.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "[507, 343]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 578.0ms\n",
      "Speed: 7.0ms preprocess, 578.0ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 543.5ms\n",
      "Speed: 14.0ms preprocess, 543.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 1 fire hydrant, 560.0ms\n",
      "Speed: 13.0ms preprocess, 560.0ms inference, 13.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 2 cars, 1 fire hydrant, 599.7ms\n",
      "Speed: 7.0ms preprocess, 599.7ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 2 cars, 665.6ms\n",
      "Speed: 8.0ms preprocess, 665.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "[158, 189]\n",
      "\n",
      "0: 320x640 1 car, 1 fire hydrant, 723.1ms\n",
      "Speed: 20.9ms preprocess, 723.1ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 car, 1 fire hydrant, 642.9ms\n",
      "Speed: 6.0ms preprocess, 642.9ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 car, 1 fire hydrant, 805.9ms\n",
      "Speed: 8.0ms preprocess, 805.9ms inference, 6.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 car, 1 fire hydrant, 574.0ms\n",
      "Speed: 12.0ms preprocess, 574.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 fire hydrant, 553.6ms\n",
      "Speed: 19.0ms preprocess, 553.6ms inference, 14.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 car, 1063.8ms\n",
      "Speed: 5.0ms preprocess, 1063.8ms inference, 9.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 car, 595.2ms\n",
      "Speed: 7.0ms preprocess, 595.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 718.1ms\n",
      "Speed: 5.0ms preprocess, 718.1ms inference, 7.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 1079.1ms\n",
      "Speed: 38.9ms preprocess, 1079.1ms inference, 11.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 (no detections), 1526.5ms\n",
      "Speed: 6.0ms preprocess, 1526.5ms inference, 9.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 2 cars, 1105.4ms\n",
      "Speed: 43.0ms preprocess, 1105.4ms inference, 13.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 car, 750.0ms\n",
      "Speed: 26.9ms preprocess, 750.0ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 car, 634.4ms\n",
      "Speed: 4.0ms preprocess, 634.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 car, 753.0ms\n",
      "Speed: 11.0ms preprocess, 753.0ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 1 fire hydrant, 651.3ms\n",
      "Speed: 7.0ms preprocess, 651.3ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 1 car, 1 fire hydrant, 543.6ms\n",
      "Speed: 18.9ms preprocess, 543.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "[592, 313]\n",
      "\n",
      "0: 320x640 2 persons, 1 car, 1 fire hydrant, 575.5ms\n",
      "Speed: 10.0ms preprocess, 575.5ms inference, 8.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 2 persons, 1 fire hydrant, 483.0ms\n",
      "Speed: 14.0ms preprocess, 483.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 2 persons, 1 car, 1 fire hydrant, 1 sheep, 488.2ms\n",
      "Speed: 8.0ms preprocess, 488.2ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 1 car, 1 fire hydrant, 1 sheep, 442.8ms\n",
      "Speed: 6.0ms preprocess, 442.8ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 car, 1 fire hydrant, 1 sheep, 503.6ms\n",
      "Speed: 8.0ms preprocess, 503.6ms inference, 7.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 463.7ms\n",
      "Speed: 5.0ms preprocess, 463.7ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 1 car, 549.7ms\n",
      "Speed: 6.0ms preprocess, 549.7ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 3 persons, 2 cars, 522.4ms\n",
      "Speed: 10.0ms preprocess, 522.4ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 454.6ms\n",
      "Speed: 7.5ms preprocess, 454.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 470.7ms\n",
      "Speed: 19.0ms preprocess, 470.7ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 408.5ms\n",
      "Speed: 6.0ms preprocess, 408.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 415.7ms\n",
      "Speed: 4.0ms preprocess, 415.7ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 2 cars, 383.4ms\n",
      "Speed: 25.0ms preprocess, 383.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 2 cars, 393.4ms\n",
      "Speed: 5.0ms preprocess, 393.4ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 405.9ms\n",
      "Speed: 19.0ms preprocess, 405.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 408.9ms\n",
      "Speed: 6.0ms preprocess, 408.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 531.3ms\n",
      "Speed: 94.3ms preprocess, 531.3ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 2 cars, 427.4ms\n",
      "Speed: 10.0ms preprocess, 427.4ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 2 cars, 395.9ms\n",
      "Speed: 7.0ms preprocess, 395.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 416.9ms\n",
      "Speed: 8.0ms preprocess, 416.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 2 cars, 402.4ms\n",
      "Speed: 5.0ms preprocess, 402.4ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 390.0ms\n",
      "Speed: 5.0ms preprocess, 390.0ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 443.8ms\n",
      "Speed: 14.0ms preprocess, 443.8ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 414.8ms\n",
      "Speed: 4.0ms preprocess, 414.8ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 433.9ms\n",
      "Speed: 5.0ms preprocess, 433.9ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 399.9ms\n",
      "Speed: 13.0ms preprocess, 399.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 432.4ms\n",
      "Speed: 6.0ms preprocess, 432.4ms inference, 7.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 388.3ms\n",
      "Speed: 8.0ms preprocess, 388.3ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 404.9ms\n",
      "Speed: 20.0ms preprocess, 404.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 414.9ms\n",
      "Speed: 6.0ms preprocess, 414.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 447.5ms\n",
      "Speed: 13.0ms preprocess, 447.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 404.7ms\n",
      "Speed: 6.0ms preprocess, 404.7ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 422.9ms\n",
      "Speed: 17.0ms preprocess, 422.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 400.4ms\n",
      "Speed: 7.0ms preprocess, 400.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 431.1ms\n",
      "Speed: 10.0ms preprocess, 431.1ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 408.7ms\n",
      "Speed: 8.5ms preprocess, 408.7ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 440.8ms\n",
      "Speed: 11.0ms preprocess, 440.8ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 405.4ms\n",
      "Speed: 6.0ms preprocess, 405.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 438.1ms\n",
      "Speed: 7.0ms preprocess, 438.1ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 604.9ms\n",
      "Speed: 8.0ms preprocess, 604.9ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2]\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 496.1ms\n",
      "Speed: 8.0ms preprocess, 496.1ms inference, 66.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19]\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 435.0ms\n",
      "Speed: 23.9ms preprocess, 435.0ms inference, 6.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19]\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 420.8ms\n",
      "Speed: 13.0ms preprocess, 420.8ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 1 traffic light, 406.9ms\n",
      "Speed: 8.0ms preprocess, 406.9ms inference, 7.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 1 traffic light, 424.9ms\n",
      "Speed: 10.0ms preprocess, 424.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 1 traffic light, 384.8ms\n",
      "Speed: 18.0ms preprocess, 384.8ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 459.8ms\n",
      "Speed: 10.5ms preprocess, 459.8ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19]\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 432.9ms\n",
      "Speed: 11.0ms preprocess, 432.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19]\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 424.9ms\n",
      "Speed: 4.0ms preprocess, 424.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19]\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 408.9ms\n",
      "Speed: 13.0ms preprocess, 408.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19]\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 436.9ms\n",
      "Speed: 4.0ms preprocess, 436.9ms inference, 6.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19]\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 413.9ms\n",
      "Speed: 5.0ms preprocess, 413.9ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19]\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 441.8ms\n",
      "Speed: 4.0ms preprocess, 441.8ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19]\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 392.0ms\n",
      "Speed: 10.0ms preprocess, 392.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19]\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 411.2ms\n",
      "Speed: 9.0ms preprocess, 411.2ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19]\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 398.9ms\n",
      "Speed: 14.5ms preprocess, 398.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 1 truck, 441.8ms\n",
      "Speed: 6.0ms preprocess, 441.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 436.3ms\n",
      "Speed: 15.0ms preprocess, 436.3ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 453.6ms\n",
      "Speed: 6.0ms preprocess, 453.6ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 424.9ms\n",
      "Speed: 3.0ms preprocess, 424.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 445.8ms\n",
      "Speed: 3.0ms preprocess, 445.8ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 399.0ms\n",
      "Speed: 7.0ms preprocess, 399.0ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17]\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 1 truck, 494.8ms\n",
      "Speed: 127.7ms preprocess, 494.8ms inference, 11.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17]\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 1 truck, 388.4ms\n",
      "Speed: 6.0ms preprocess, 388.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17]\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 455.8ms\n",
      "Speed: 13.0ms preprocess, 455.8ms inference, 6.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17]\n",
      "\n",
      "0: 320x640 1 person, 6 cars, 442.4ms\n",
      "Speed: 4.0ms preprocess, 442.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17]\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 426.4ms\n",
      "Speed: 4.0ms preprocess, 426.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17]\n",
      "\n",
      "0: 320x640 1 person, 5 cars, 385.0ms\n",
      "Speed: 4.0ms preprocess, 385.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 419.5ms\n",
      "Speed: 11.0ms preprocess, 419.5ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17]\n",
      "\n",
      "0: 320x640 3 cars, 393.7ms\n",
      "Speed: 4.0ms preprocess, 393.7ms inference, 6.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17]\n",
      "\n",
      "0: 320x640 3 cars, 461.2ms\n",
      "Speed: 7.0ms preprocess, 461.2ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17]\n",
      "[672, 282]\n",
      "\n",
      "0: 320x640 3 cars, 439.3ms\n",
      "Speed: 10.0ms preprocess, 439.3ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "[880, 194]\n",
      "\n",
      "0: 320x640 3 cars, 457.3ms\n",
      "Speed: 7.0ms preprocess, 457.3ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "[550, 240]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 458.3ms\n",
      "Speed: 10.0ms preprocess, 458.3ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "[17, 240]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 592.9ms\n",
      "Speed: 5.5ms preprocess, 592.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "\n",
      "0: 320x640 4 cars, 435.8ms\n",
      "Speed: 13.0ms preprocess, 435.8ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 422.8ms\n",
      "Speed: 8.0ms preprocess, 422.8ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 418.4ms\n",
      "Speed: 6.0ms preprocess, 418.4ms inference, 8.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 423.9ms\n",
      "Speed: 16.0ms preprocess, 423.9ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 426.9ms\n",
      "Speed: 3.0ms preprocess, 426.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 499.7ms\n",
      "Speed: 19.9ms preprocess, 499.7ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "\n",
      "0: 320x640 1 person, 2 cars, 486.3ms\n",
      "Speed: 5.0ms preprocess, 486.3ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "[71, 368]\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 462.8ms\n",
      "Speed: 12.0ms preprocess, 462.8ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 468.3ms\n",
      "Speed: 12.0ms preprocess, 468.3ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 711.6ms\n",
      "Speed: 12.0ms preprocess, 711.6ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 548.5ms\n",
      "Speed: 151.6ms preprocess, 548.5ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "\n",
      "0: 320x640 1 person, 4 cars, 466.7ms\n",
      "Speed: 7.0ms preprocess, 466.7ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "\n",
      "0: 320x640 2 persons, 3 cars, 577.5ms\n",
      "Speed: 16.0ms preprocess, 577.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "\n",
      "0: 320x640 2 persons, 2 cars, 542.5ms\n",
      "Speed: 3.0ms preprocess, 542.5ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 430.6ms\n",
      "Speed: 18.0ms preprocess, 430.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 452.6ms\n",
      "Speed: 13.0ms preprocess, 452.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 417.4ms\n",
      "Speed: 4.0ms preprocess, 417.4ms inference, 6.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 439.8ms\n",
      "Speed: 7.0ms preprocess, 439.8ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 453.8ms\n",
      "Speed: 5.0ms preprocess, 453.8ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "\n",
      "0: 320x640 1 person, 3 cars, 403.4ms\n",
      "Speed: 5.0ms preprocess, 403.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "\n",
      "0: 320x640 3 cars, 375.0ms\n",
      "Speed: 4.0ms preprocess, 375.0ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "\n",
      "0: 320x640 3 cars, 1 traffic light, 434.6ms\n",
      "Speed: 4.0ms preprocess, 434.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "[647, 436]\n",
      "[647, 436]\n",
      "\n",
      "0: 320x640 3 cars, 1 traffic light, 441.1ms\n",
      "Speed: 22.9ms preprocess, 441.1ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "[662, 250]\n",
      "\n",
      "0: 320x640 3 cars, 396.9ms\n",
      "Speed: 5.0ms preprocess, 396.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "[201, 186]\n",
      "\n",
      "0: 320x640 3 cars, 625.0ms\n",
      "Speed: 15.0ms preprocess, 625.0ms inference, 8.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "\n",
      "0: 320x640 3 cars, 1 fire hydrant, 484.0ms\n",
      "Speed: 8.0ms preprocess, 484.0ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n",
      "\n",
      "0: 320x640 3 cars, 2 fire hydrants, 402.9ms\n",
      "Speed: 6.0ms preprocess, 402.9ms inference, 5.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "[1, 0, 2, 19, 17, 21]\n"
     ]
    }
   ],
   "source": [
    "def RGB(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_MOUSEMOVE :  \n",
    "        colorsBGR = [x, y]\n",
    "        print(colorsBGR)\n",
    "        \n",
    "\n",
    "cv2.namedWindow('RGB')\n",
    "cv2.setMouseCallback('RGB', RGB)\n",
    "\n",
    "cap=cv2.VideoCapture('veh2.mp4')\n",
    "\n",
    "\n",
    "my_file = open(\"coco.txt\", \"r\")\n",
    "data = my_file.read()\n",
    "class_list = data.split(\"\\n\") \n",
    "#print(class_list)\n",
    "\n",
    "count=0\n",
    "\n",
    "tracker=Tracker()\n",
    "\n",
    "cy1=323\n",
    "cy2=367\n",
    "offset=6\n",
    "\n",
    "vh_down={}\n",
    "counter=[]\n",
    "\n",
    "vh_up={}\n",
    "counter1=[]\n",
    "\n",
    "\n",
    "while True:    \n",
    "    ret,frame = cap.read()\n",
    "    fps = FPS().start() \n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    count += 1\n",
    "    if count % 3 != 0:\n",
    "        continue\n",
    "    frame=cv2.resize(frame,(1020,500))\n",
    "   \n",
    "\n",
    "    results=model.predict(frame)\n",
    "    fps.update()\n",
    "    fps.stop()\n",
    " #   print(results)\n",
    "    a=results[0].boxes.data\n",
    "    px=pd.DataFrame(a).astype(\"float\")\n",
    "#    print(px)\n",
    "    list=[]\n",
    "             \n",
    "    for index,row in px.iterrows():\n",
    "#        print(row)\n",
    " \n",
    "        x1=int(row[0])\n",
    "        y1=int(row[1])\n",
    "        x2=int(row[2])\n",
    "        y2=int(row[3])\n",
    "        d=int(row[5])\n",
    "        c=class_list[d]\n",
    "        if 'car' in c:\n",
    "            list.append([x1,y1,x2,y2])\n",
    "    bbox_id=tracker.update(list)\n",
    "    for bbox in bbox_id:\n",
    "        x3,y3,x4,y4,id=bbox\n",
    "        cx=int(x3+x4)//2\n",
    "        cy=int(y3+y4)//2\n",
    "        \n",
    "        if cy1<(cy+offset) and cy1>(cy-offset):\n",
    "            vh_down[id]=cy\n",
    "        if id in vh_down:\n",
    "            if cy2<(cy+offset) and cy2>(cy-offset):\n",
    "                cv2.circle(frame,(cx,cy),4,(0,0,255),-1)\n",
    "                cv2.putText(frame,str(id),(cx,cy),cv2.FONT_HERSHEY_COMPLEX,0.8,(0,255,255),2)\n",
    "                if counter.count(id)==0:\n",
    "                    counter.append(id)\n",
    "        ##Going down\n",
    "        if cy2<(cy+offset) and cy2>(cy-offset):\n",
    "            vh_up[id]=cy\n",
    "        if id in vh_up:\n",
    "            if cy1<(cy+offset) and cy1>(cy-offset):\n",
    "                cv2.circle(frame,(cx,cy),4,(0,0,255),-1)\n",
    "                cv2.putText(frame,str(id),(cx,cy),cv2.FONT_HERSHEY_COMPLEX,0.8,(0,255,255),2)\n",
    "                if counter1.count(id)==0:\n",
    "                    counter1.append(id)\n",
    "\n",
    "    cv2.line(frame,(259,cy1),(811,cy1),(255,255,255),1)\n",
    "    cv2.putText(frame,('1line'),(274,318),cv2.FONT_HERSHEY_COMPLEX,0.8,(0,255,255),2)\n",
    "\n",
    "    cv2.line(frame,(154,cy2),(913,cy2),(255,255,255),1)\n",
    "    cv2.putText(frame,('2line'),(154,365),cv2.FONT_HERSHEY_COMPLEX,0.8,(0,255,255),2)\n",
    "    d=(len(counter))\n",
    "    cv2.putText(frame,('goingdown: -')+str(d),(60,40),cv2.FONT_HERSHEY_COMPLEX,0.8,(0,255,255),2)\n",
    "    u=(len(counter1))\n",
    "    cv2.putText(frame,('goingup: -')+str(u),(60,130),cv2.FONT_HERSHEY_COMPLEX,0.8,(0,255,255),2)\n",
    "    \n",
    "    txt_fps = \"FPS: {:.2f}\".format(fps.fps())\n",
    "    cv2.putText(frame, txt_fps,(60,180),cv2.FONT_HERSHEY_COMPLEX,0.8,(0,255,255),2)\n",
    "    print(counter)\n",
    "    cv2.imshow(\"RGB\", frame)\n",
    "    if cv2.waitKey(1)&0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
